{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from keras import *\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow import math\n",
    "from plot_keras_history import plot_history\n",
    "\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        1\n",
       "2        5\n",
       "3        5\n",
       "4        5\n",
       "        ..\n",
       "11495    2\n",
       "11496    1\n",
       "11497    5\n",
       "11498    3\n",
       "11499    4\n",
       "Name: y, Length: 11500, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pandas.read_csv(\"bonn_dataset.csv\")\n",
    "\n",
    "labels = data_frame['y']\n",
    "first_column = data_frame.columns[0]\n",
    "data = data_frame.copy()\n",
    "data.pop(first_column)\n",
    "data.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.shape[1])\n",
    "\n",
    "\n",
    "filtered = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # decompose the signal 5 levels\n",
    "    vec = data.iloc[i]\n",
    "    coefficients = pywt.wavedec(vec, 'db5', 5)\n",
    "        \n",
    "    filtered.append(np.array(coefficients))\n",
    "    \n",
    "filtered = np.array(filtered)\n",
    "# print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 178, 1)            0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 14,269\n",
      "Trainable params: 14,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \n",
    "def rnn(shape):\n",
    "    model = Sequential(name='rnn')\n",
    "\n",
    "    inputs = Input(shape=shape)\n",
    "    \n",
    "    model.add(inputs)\n",
    "    model.add(layers.Reshape(shape))\n",
    "#     model.add(layers.Embedding(shape[0] + 1, 86))\n",
    "    \n",
    "    model.add(layers.GRU(64))\n",
    "    \n",
    "    model.add(layers.Dense(20, activation='sigmoid'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "    \n",
    "#     model.add(layers.Reshape((data.shape[1], 1)))\n",
    "    # model.add(layers.Conv1D(64, 25, activation='relu'))\n",
    "#     model.add(layers.Conv1D(32, 15, activation='relu'))\n",
    "#     model.add(layers.Conv1D(16, 10, activation='relu'))\n",
    "#     model.add(layers.Conv1D(8, 5, activation='relu'))\n",
    "#     model.add(layers.MaxPooling1D())\n",
    "#     model.add(layers.Flatten())\n",
    "#     # model.add(layers.Dense(100, activation='sigmoid'))\n",
    "#     model.add(layers.Dense(40, activation='sigmoid'))\n",
    "#     model.add(layers.Dropout(0.5))\n",
    "#     model.add(layers.Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "rnn((data.shape[1], 1)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 1.2680 - accuracy: 0.4690\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.9502 - accuracy: 0.5941\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 23s 85ms/step - loss: 0.8471 - accuracy: 0.6279\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 24s 87ms/step - loss: 0.7775 - accuracy: 0.6602\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.7365 - accuracy: 0.66810s - loss: 0.7376 - accuracy\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 24s 88ms/step - loss: 0.7142 - accuracy: 0.6780\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 24s 88ms/step - loss: 0.6825 - accuracy: 0.6881\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 24s 87ms/step - loss: 0.6862 - accuracy: 0.6878\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 23s 87ms/step - loss: 0.6604 - accuracy: 0.6933\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.6595 - accuracy: 0.6955\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 0.6445 - accuracy: 0.7024\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 0.6293 - accuracy: 0.70900s - loss: 0.628\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 24s 91ms/step - loss: 0.6227 - accuracy: 0.7132\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 24s 89ms/step - loss: 0.6133 - accuracy: 0.7147\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 23s 85ms/step - loss: 0.6216 - accuracy: 0.7133\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 0.5993 - accuracy: 0.7252\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 25s 93ms/step - loss: 0.5923 - accuracy: 0.7299\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 0.5882 - accuracy: 0.7295\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 25s 94ms/step - loss: 0.5918 - accuracy: 0.7299\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 26s 96ms/step - loss: 0.5794 - accuracy: 0.7351\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 0.5788 - accuracy: 0.7379\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 0.5631 - accuracy: 0.7417\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 25s 93ms/step - loss: 0.5609 - accuracy: 0.7443\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 26s 95ms/step - loss: 0.5523 - accuracy: 0.74763s - loss: 0.5\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 25s 91ms/step - loss: 0.5521 - accuracy: 0.7466\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 26s 94ms/step - loss: 0.5458 - accuracy: 0.7550\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 25s 92ms/step - loss: 0.5414 - accuracy: 0.7566\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 25s 93ms/step - loss: 0.5404 - accuracy: 0.7612\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 25s 92ms/step - loss: 0.5387 - accuracy: 0.7592\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 25s 92ms/step - loss: 0.5354 - accuracy: 0.7632\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 25s 94ms/step - loss: 0.5288 - accuracy: 0.7638\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 0.5224 - accuracy: 0.7608\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 18s 67ms/step - loss: 0.5385 - accuracy: 0.7577\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 19s 71ms/step - loss: 0.5166 - accuracy: 0.7674\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 21s 78ms/step - loss: 0.5088 - accuracy: 0.7730\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 21s 78ms/step - loss: 0.5123 - accuracy: 0.7721\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 22s 80ms/step - loss: 0.5061 - accuracy: 0.7743\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 0.4986 - accuracy: 0.7803\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 21s 79ms/step - loss: 0.4981 - accuracy: 0.7811\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 0.4942 - accuracy: 0.7834\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.4876 - accuracy: 0.7838\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.4893 - accuracy: 0.7860\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.4822 - accuracy: 0.7838\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.4715 - accuracy: 0.7923\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 23s 84ms/step - loss: 0.4737 - accuracy: 0.7933\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 23s 84ms/step - loss: 0.4735 - accuracy: 0.7928\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 23s 83ms/step - loss: 0.4661 - accuracy: 0.7939\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.4534 - accuracy: 0.8022\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.4661 - accuracy: 0.7970\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 22s 82ms/step - loss: 0.4501 - accuracy: 0.8088\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, pandas.get_dummies(labels, prefix='state'))\n",
    "\n",
    "model = rnn((data.shape[1], 1))\n",
    "model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 2s 17ms/step - loss: 0.6467 - accuracy: 0.7353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6467121243476868, 0.7353043556213379]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# row.plot()\n",
    "# pyplot.show()\n",
    "\n",
    "filtered_data = []\n",
    "wavelets = ['db6', 'sym6', 'coif2'] # all these wavelets produce coefficients of the same length\n",
    "\n",
    "# row = data.iloc[0]\n",
    "# ca, cd = pywt.dwt(row, 'coif2')\n",
    "# print(len(cd))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    row = data.iloc[i]\n",
    "    \n",
    "    new_row = []\n",
    "    \n",
    "    for wt in wavelets:\n",
    "        ca, cd = pywt.dwt(row, wt)\n",
    "        new_row.append(ca)\n",
    "        new_row.append(cd)\n",
    "    \n",
    "    filtered_data.append(np.array(new_row))\n",
    "\n",
    "filtered_data = np.array(filtered_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"filtered\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_14 (Reshape)         (None, 94, 6)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 80, 32)            2912      \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 71, 16)            5136      \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 67, 8)             648       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 33, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 50)                13250     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 22,201\n",
      "Trainable params: 22,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print(filtered_data)\n",
    "def filtered_cnn(shape):\n",
    "    model = Sequential(name='filtered')\n",
    "    model.add(Input(shape=shape[1:]))\n",
    "    model.add(layers.Reshape((shape[2], shape[1])))\n",
    "    model.add(layers.Conv1D(32, 15, activation='relu'))\n",
    "    model.add(layers.Conv1D(16, 10, activation='relu'))\n",
    "    model.add(layers.Conv1D(8, 5, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D())\n",
    "    model.add(layers.Flatten())\n",
    "    # model.add(layers.Dense(100, activation='sigmoid'))\n",
    "    model.add(layers.Dense(50, activation='sigmoid'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "          \n",
    "filtered_cnn(filtered_data.shape).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 0\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.3265 - accuracy: 0.3904\n",
      "Test Loss: 1.3264912366867065\n",
      "Test Accuracy: 0.39043477177619934\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 1\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1013 - accuracy: 0.5052\n",
      "Test Loss: 1.1012675762176514\n",
      "Test Accuracy: 0.5052173733711243\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 2\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9355 - accuracy: 0.5722\n",
      "Test Loss: 0.9354562163352966\n",
      "Test Accuracy: 0.5721738934516907\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 3\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.5513\n",
      "Test Loss: 1.008253812789917\n",
      "Test Accuracy: 0.5513043403625488\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 4\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.7017\n",
      "Test Loss: 0.6333645582199097\n",
      "Test Accuracy: 0.7017391324043274\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1929 - accuracy: 0.4357\n",
      "Test Loss: 1.1928826570510864\n",
      "Test Accuracy: 0.4356521666049957\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 6\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.3573 - accuracy: 0.3896\n",
      "Test Loss: 1.3573065996170044\n",
      "Test Accuracy: 0.38956522941589355\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 7\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9332 - accuracy: 0.5609\n",
      "Test Loss: 0.9331607818603516\n",
      "Test Accuracy: 0.560869574546814\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 8\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.2551 - accuracy: 0.4800\n",
      "Test Loss: 1.25507390499115\n",
      "Test Accuracy: 0.47999998927116394\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Training for fold nr: 9\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.2062 - accuracy: 0.4800\n",
      "Test Loss: 1.2062236070632935\n",
      "Test Accuracy: 0.47999998927116394\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1337)\n",
    "\n",
    "accuracy_fold = []\n",
    "loss_fold = []\n",
    "\n",
    "fold_nr = 0\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(filtered_data, labels):\n",
    "    x_train = filtered_data[train_indexes]\n",
    "    y_train_multilabel = labels.iloc[train_indexes]\n",
    "    y_train = pandas.get_dummies(y_train_multilabel, prefix='state')\n",
    "    \n",
    "    \n",
    "    x_test = filtered_data[test_indexes]\n",
    "    y_test_multilabel = labels.iloc[test_indexes]\n",
    "    y_test = pandas.get_dummies(y_test_multilabel, prefix='state')\n",
    "    \n",
    "    # define a new model\n",
    "    model = filtered_cnn(filtered_data.shape)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(\"Training for fold nr: {}\".format(fold_nr))\n",
    "    history = model.fit(x_train, y_train, batch_size=32, epochs=50, verbose=0)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    print(\"Test Loss: {}\".format(loss))\n",
    "    print(\"Test Accuracy: {}\".format(accuracy))\n",
    "    \n",
    "    accuracy_fold.append(accuracy)\n",
    "    loss_fold.append(loss)\n",
    "    \n",
    "    fold_nr += 1\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "# y = pandas.get_dummies(labels, prefix='state')\n",
    "# # print(y)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(filtered_data, y, test_size=0.1, random_state=1337)\n",
    "# model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(x_train, y_train, batch_size=32, epochs=40)\n",
    "# loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss for the model: 1.0949480950832366\n",
      "Average accuracy for the model: 0.5066956460475922\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Loss for the model: {}\".format(sum(loss_fold) / 10))\n",
    "print(\"Average accuracy for the model: {}\".format(sum(accuracy_fold) / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
